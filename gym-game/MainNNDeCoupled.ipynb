{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/esha/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Maze/Maze.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Maths/Cord.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Maze/MazeGenerator.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Agents/Worker.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Maths/Action.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Maths/State.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Agents/Prey.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Agents/Agent.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Main/Simulator.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Windows/MainWindow.ipynb\n",
      "Importing Jupyter notebook from /home/esha/anaconda3/Scripts/gym-game/Maths/DQNSolver.ipynb\n",
      "Name: Test\n",
      "10x10\n",
      "Start: (4, 0)\n",
      "End: (4, 9) \n",
      "1111311111 9\n",
      "1000000001 8\n",
      "1001010101 7\n",
      "1000000001 6\n",
      "1101100011 5\n",
      "1000010111 4\n",
      "1000000001 3\n",
      "1110011001 2\n",
      "1000000001 1\n",
      "1111211111 0\n",
      "Test Run: 1, No of Steps: 4223 Total Reward: -263181661 14 4134.5\n",
      "Test Run: 2, No of Steps: 147 Total Reward: -10522055 14 147.0\n",
      "Test Run: 3, No of Steps: 135 Total Reward: -4434563 14 135.0\n",
      "Test Run: 4, No of Steps: 15 Total Reward: 70054 14 15.0\n",
      "Test Run: 5, No of Steps: 19 Total Reward: 856550 14 19.0\n",
      "Test Run: 6, No of Steps: 18 Total Reward: 1573642 14 18.0\n",
      "Test Run: 7, No of Steps: 118 Total Reward: 14477562 14 115.0\n",
      "Test Run: 8, No of Steps: 121 Total Reward: 19302965 14 98.5\n",
      "Test Run: 9, No of Steps: 24 Total Reward: 4219456 14 22.5\n",
      "Test Run: 10, No of Steps: 37 Total Reward: 7895971 14 36.5\n",
      "Test Run: 11, No of Steps: 25 Total Reward: 6491339 14 20.0\n",
      "Test Run: 12, No of Steps: 32 Total Reward: 9388725 14 27.5\n",
      "Test Run: 13, No of Steps: 29 Total Reward: 9264440 14 17.0\n",
      "Test Run: 14, No of Steps: 29 Total Reward: 10088172 14 15.0\n",
      "Test Run: 15, No of Steps: 15 Total Reward: 5674594 14 15.0\n",
      "Test Run: 16, No of Steps: 19 Total Reward: 8012464 14 17.0\n",
      "Test Run: 17, No of Steps: 16 Total Reward: 7288790 14 15.0\n",
      "Test Run: 18, No of Steps: 16 Total Reward: 7937698 14 15.0\n",
      "Test Run: 19, No of Steps: 15 Total Reward: 8015854 14 15.0\n",
      "Test Run: 20, No of Steps: 20 Total Reward: 11450064 14 15.0\n",
      "Test Run: 21, No of Steps: 17 Total Reward: 10393551 14 16.0\n",
      "Test Run: 22, No of Steps: 15 Total Reward: 9726844 14 15.0\n",
      "Test Run: 23, No of Steps: 17 Total Reward: 11723846 14 15.0\n",
      "Test Run: 24, No of Steps: 15 Total Reward: 10897564 14 15.0\n",
      "Test Run: 25, No of Steps: 15 Total Reward: 11497924 14 15.0\n",
      "Test Run: 26, No of Steps: 15 Total Reward: 12098284 14 15.0\n",
      "Test Run: 27, No of Steps: 17 Total Reward: 14395990 14 15.0\n",
      "Test Run: 28, No of Steps: 15 Total Reward: 13269004 14 15.0\n",
      "Test Run: 29, No of Steps: 15 Total Reward: 13869364 14 15.0\n",
      "Test Run: 30, No of Steps: 16 Total Reward: 15449731 14 15.0\n",
      "Test Run: 31, No of Steps: 15 Total Reward: 15055084 14 15.0\n",
      "Test Run: 32, No of Steps: 15 Total Reward: 15655444 14 15.0\n",
      "Test Run: 33, No of Steps: 15 Total Reward: 16255804 14 15.0\n",
      "Test Run: 34, No of Steps: 17 Total Reward: 19136753 14 16.0\n",
      "Test Run: 35, No of Steps: 15 Total Reward: 17441434 14 15.0\n",
      "Test Run: 36, No of Steps: 15 Total Reward: 18041794 14 15.0\n",
      "Test Run: 37, No of Steps: 15 Total Reward: 18642154 14 15.0\n",
      "Test Run: 38, No of Steps: 15 Total Reward: 19242514 14 15.0\n",
      "Test Run: 39, No of Steps: 15 Total Reward: 19842874 14 15.0\n",
      "Test Run: 40, No of Steps: 15 Total Reward: 20443234 14 15.0\n",
      "Test Run: 41, No of Steps: 17 Total Reward: 23882749 14 16.5\n",
      "Test Run: 42, No of Steps: 15 Total Reward: 21635854 14 15.0\n",
      "Test Run: 43, No of Steps: 15 Total Reward: 22236214 14 15.0\n",
      "Test Run: 44, No of Steps: 16 Total Reward: 24376127 14 16.0\n",
      "Test Run: 45, No of Steps: 159 Total Reward: 245718133 14 87.0\n",
      "Test Run: 46, No of Steps: 15 Total Reward: 22956994 14 15.0\n",
      "Test Run: 47, No of Steps: 15 Total Reward: 23557354 14 15.0\n",
      "Test Run: 48, No of Steps: 15 Total Reward: 24157714 14 15.0\n",
      "Test Run: 49, No of Steps: 15 Total Reward: 24758074 14 15.0\n",
      "Test Run: 50, No of Steps: 15 Total Reward: 25358434 14 15.0\n",
      "Test Run: 51, No of Steps: 16 Total Reward: 27698730 14 15.5\n",
      "Test Run: 52, No of Steps: 15 Total Reward: 26551654 14 15.0\n",
      "Test Run: 53, No of Steps: 15 Total Reward: 27152014 14 15.0\n",
      "Test Run: 54, No of Steps: 15 Total Reward: 27752374 14 15.0\n",
      "Test Run: 55, No of Steps: 16 Total Reward: 30255757 14 15.5\n",
      "Test Run: 56, No of Steps: 15 Total Reward: 28945594 14 15.0\n",
      "Test Run: 57, No of Steps: 15 Total Reward: 29545954 14 15.0\n",
      "Test Run: 58, No of Steps: 15 Total Reward: 30146314 14 15.0\n",
      "Test Run: 59, No of Steps: 17 Total Reward: 34880945 14 17.0\n",
      "Test Run: 60, No of Steps: 15 Total Reward: 31347034 14 15.0\n",
      "Test Run: 61, No of Steps: 15 Total Reward: 31947394 14 15.0\n",
      "Test Run: 62, No of Steps: 16 Total Reward: 34734811 14 16.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0047c5ef784f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0047c5ef784f>\u001b[0m in \u001b[0;36mGame\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m#action = dqn_solver.act(state)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m#print(\"Action \",action, env.action_space[action])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;31m#state_next, reward, terminal, info = env.step(action)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m#reward = reward if not terminal else -reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/Scripts/gym-game/gym_game/envs/game_env.py\u001b[0m in \u001b[0;36mstepAll\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn_solver_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstate_next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn_solver_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCordToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/Scripts/gym-game/Maths/DQNSolver.ipynb\u001b[0m in \u001b[0;36mexperience_replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;34m\"    def experience_replay(self):\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m\"        if len(self.memory) < self.BATCH_SIZE:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;34m\"            return\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;34m\"        batch = random.sample(self.memory, self.BATCH_SIZE)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;34m\"        for state, action, reward, state_next, terminal in batch:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import gym_game\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "ENV_NAME = \"game-v0\"\n",
    "\n",
    "\n",
    "def Game():\n",
    "    env = gym.make(ENV_NAME)    \n",
    "    #observation_space = int(env.observation_space )         #\n",
    "    #action_space = len(env.action_space)                            #\n",
    "    #dqn_solver = DQNSolver(observation_space, action_space)\n",
    "    run = 0\n",
    "    count=0\n",
    "    while True:\n",
    "        run += 1\n",
    "        #state=env.reset()\n",
    "        if(count<5):\n",
    "            state = env.reset()  \n",
    "        else:\n",
    "            print(\" \")\n",
    "            state=env.resetNewMaze()\n",
    "            count=0\n",
    "            \n",
    "        #state = np.reshape(state,  [1,observation_space])\n",
    "        step = 0\n",
    "        stepsNo=0\n",
    "        totReward=0\n",
    "        while True:\n",
    "            step += 1\n",
    "            #env.render()\n",
    "            #action = dqn_solver.act(state)\n",
    "            #print(\"Action \",action, env.action_space[action])\n",
    "            reward, terminal=env.stepAll()\n",
    "            #state_next, reward, terminal, info = env.step(action)  \n",
    "            #reward = reward if not terminal else -reward\n",
    "            #state_next = np.reshape(state_next, [1,observation_space])\n",
    "            #dqn_solver.remember(state, action, reward, state_next, terminal)\n",
    "            #state = state_next\n",
    "            totReward+=reward\n",
    "            if (terminal):\n",
    "                print (env.maze.name,\"Run: \" + str(run) + \", No of Steps: \" + str(step), \"Total Reward:\",totReward,env.shortestRoute, env.count/env.number)\n",
    "                file=open(\"RunsData.txt\",\"a+\")\n",
    "                file.write(env.maze.name+\" \"+str(run)+\" \"+str(step)+\" \"+str(totReward)+\" \"+str(env.count/env.number)+\"\\n\")\n",
    "                file.close()\n",
    "                if(step<=env.shortestRoute):\n",
    "                    count+=0\n",
    "                break\n",
    "            #dqn_solver.experience_replay()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Game()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
